{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper for Retro Contest\n",
    "### Author: seungjaeryanlee\n",
    "\n",
    "This is a simple scraper using urllib3 and BeautifulSoup4 to scraper 'Your Jobs' page for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cookies():\n",
    "    \"\"\"\n",
    "    Get cookies from cookies.txt.\n",
    "    \"\"\"\n",
    "    with open('cookies.txt', 'r') as file:\n",
    "        session = file.readline().strip()\n",
    "        remember_token = file.readline().strip()\n",
    "\n",
    "    return (session, remember_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(session, remember_token):\n",
    "    \"\"\"\n",
    "    Retrieve page with urllib with given cookies.\n",
    "    \"\"\"\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders.append(('Cookie', 'session={}'.format(session)))\n",
    "    opener.addheaders.append(('Cookie', 'remember_token={}'.format(remember_token)))\n",
    "    page = opener.open(\"https://contest.openai.com/user/job\").read()\n",
    "\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_info(page):\n",
    "    \"\"\"\n",
    "    Use BeautifulSoup4 to parse info from HTML page.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page, 'html5lib')\n",
    "    info = {}\n",
    "\n",
    "    # Get summary info\n",
    "    job_div = soup.find('div', {'class': 'job'})\n",
    "    job_div_dds = job_div.find('dl').find_all('dd')\n",
    "\n",
    "    status = job_div_dds[0].contents[0].strip()\n",
    "    docker_name = job_div_dds[1].contents[0].strip()\n",
    "    start_time = job_div_dds[2].contents[0].strip()\n",
    "    eta = job_div_dds[3].contents[0].strip()\n",
    "    score = job_div_dds[4].contents[0].strip()\n",
    "\n",
    "    info['summary'] = {}\n",
    "    info['summary']['status'] = status\n",
    "    info['summary']['docker_name'] = docker_name\n",
    "    info['summary']['start_time'] = start_time\n",
    "    info['summary']['eta'] = eta\n",
    "    info['summary']['score'] = score\n",
    "\n",
    "    # Get individual task infos\n",
    "    worker_info_table = soup.find('table', {'class': 'worker_info'})\n",
    "    worker_info_table_trs = worker_info_table.find_all('tr')\n",
    "\n",
    "    info['tasks'] = []\n",
    "    for i in range(1, len(worker_info_table_trs)):\n",
    "        tds = worker_info_table_trs[i].find_all('td')\n",
    "        task = tds[0].contents[0].strip()\n",
    "        status = tds[1].contents[0].strip()\n",
    "        score = tds[2].contents[0].strip()\n",
    "        progress = tds[3].contents[0].strip()\n",
    "        eta = tds[4].contents[0].strip().replace(' ', '').replace('\\n', '')\n",
    "        error = ''.join(tds[5].contents)\n",
    "\n",
    "        task_info = {}\n",
    "        task_info['task'] = task\n",
    "        task_info['status'] = status\n",
    "        task_info['score'] = score\n",
    "        task_info['progress'] = progress\n",
    "        task_info['eta'] = eta\n",
    "        task_info['error'] = error\n",
    "        info['tasks'].append(task_info)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_to_log(info):\n",
    "    \"\"\"\n",
    "    Formats info to a single-line string to save.\n",
    "    \"\"\"\n",
    "    log = '{:30} | {:20} | {:>7} | {:>7}'.format(\n",
    "        str(datetime.now()),\n",
    "        info['summary']['docker_name'],\n",
    "        info['summary']['status'],\n",
    "        info['summary']['score'],\n",
    "    )\n",
    "    for i in range(5):\n",
    "        log += ' | {:2} | {:7} | {:5} | {:>7}'.format(\n",
    "            info['tasks'][i]['task'],\n",
    "            info['tasks'][i]['status'],\n",
    "            info['tasks'][i]['progress'],\n",
    "            info['tasks'][i]['score'],\n",
    "        )\n",
    "    log += '\\n'\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(log):\n",
    "    with open('info.txt', 'a+') as file:\n",
    "        file.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def auto_log(interval_in_sec):\n",
    "    \"\"\"\n",
    "    Log lastest info automatically with given interval in seconds.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        session, remember_token = get_cookies()\n",
    "        page = get_page(session, remember_token)\n",
    "        info = page_to_info(page)\n",
    "        log = info_to_log(info)\n",
    "        save_log(log)\n",
    "\n",
    "        time.sleep(interval_in_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_log(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:retroai]",
   "language": "python",
   "name": "conda-env-retroai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
